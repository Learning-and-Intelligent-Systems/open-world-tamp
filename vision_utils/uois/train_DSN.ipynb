{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Depth Seeding Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# My libraries\n",
    "import src.data_loader as data_loader\n",
    "import src.segmentation as segmentation\n",
    "import src.train as train\n",
    "import src.util.utilities as util_\n",
    "import src.util.flowlib as flowlib\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\" # TODO: Change this if you have more than 1 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Dataset: TableTop Object Dataset (TOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOD_filepath = '...' # TODO: change this to the dataset you want to train on\n",
    "data_loading_params = {\n",
    "    \n",
    "    # Camera/Frustum parameters\n",
    "    'img_width' : 640, \n",
    "    'img_height' : 480,\n",
    "    'near' : 0.01,\n",
    "    'far' : 100,\n",
    "    'fov' : 45, # vertical field of view in degrees\n",
    "    \n",
    "    'use_data_augmentation' : True,\n",
    "\n",
    "    # Multiplicative noise\n",
    "    'gamma_shape' : 1000.,\n",
    "    'gamma_scale' : 0.001,\n",
    "    \n",
    "    # Additive noise\n",
    "    'gaussian_scale_range' : [0., 0.003], # up to 2.5mm standard dev\n",
    "    'gp_rescale_factor_range' : [12, 20], # [low, high (exclusive)]\n",
    "    \n",
    "    # Random ellipse dropout\n",
    "    'ellipse_dropout_mean' : 10, \n",
    "    'ellipse_gamma_shape' : 5.0, \n",
    "    'ellipse_gamma_scale' : 1.0,\n",
    "\n",
    "    # Random high gradient dropout\n",
    "    'gradient_dropout_left_mean' : 15, \n",
    "    'gradient_dropout_alpha' : 2., \n",
    "    'gradient_dropout_beta' : 5.,\n",
    "\n",
    "    # Random pixel dropout\n",
    "    'pixel_dropout_alpha' : 0.2, \n",
    "    'pixel_dropout_beta' : 10.,\n",
    "    \n",
    "}\n",
    "dl = data_loader.get_TOD_train_dataloader(TOD_filepath, data_loading_params, batch_size=4, num_workers=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Depth Seeding Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsn_config = {\n",
    "    \n",
    "    # Sizes\n",
    "    'feature_dim' : 64, # 32 would be normal\n",
    "\n",
    "    # Mean Shift parameters (for 3D voting)\n",
    "    'max_GMS_iters' : 10, \n",
    "    'num_seeds' : 200, # Used for MeanShift, but not BlurringMeanShift\n",
    "    'epsilon' : 0.05, # Connected Components parameter\n",
    "    'sigma' : 0.02, # Gaussian bandwidth parameter\n",
    "    'subsample_factor' : 5,\n",
    "    'min_pixels_thresh' : 500,\n",
    "    \n",
    "    # Differentiable backtracing params\n",
    "    'tau' : 15.,\n",
    "    'M_threshold' : 0.3,\n",
    "    \n",
    "    # Robustness stuff\n",
    "    'angle_discretization' : 100,\n",
    "    'discretization_threshold' : 0.,\n",
    "\n",
    "}\n",
    "\n",
    "tb_dir = ... # TODO: change this to desired tensorboard directory\n",
    "dsn_training_config = {\n",
    "    \n",
    "    # Training parameters\n",
    "    'lr' : 1e-4, # learning rate\n",
    "    'iter_collect' : 20, # Collect results every _ iterations\n",
    "    'max_iters' : 150000,\n",
    "    \n",
    "    # Loss function stuff\n",
    "    'lambda_fg' : 3.,\n",
    "    'lambda_co' : 5., \n",
    "    'lambda_sep' : 1., \n",
    "    'lambda_cl' : 1.,\n",
    "    'num_seeds_training' : 50, \n",
    "    'delta' : 0.1, # for clustering loss. 2*eps\n",
    "    'max_GMS_iters' : 10, \n",
    "\n",
    "    # Tensorboard stuff\n",
    "    'tb_directory' : os.path.join(tb_dir, 'train_DSN/'),\n",
    "    'flush_secs' : 10, # Write tensorboard results every _ seconds\n",
    "}\n",
    "\n",
    "iter_num = 0\n",
    "dsn_training_config.update({\n",
    "    # Starting optimization from previous checkpoint\n",
    "    'load' : False,\n",
    "    'opt_filename' : os.path.join(dsn_training_config['tb_directory'],\n",
    "                                  f'DSNTrainer_DSNWrapper_{iter_num}_checkpoint.pth'),\n",
    "    'model_filename' : os.path.join(dsn_training_config['tb_directory'],\n",
    "                                    f'DSNTrainer_DSNWrapper_{iter_num}_checkpoint.pth'),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsn = segmentation.DSNWrapper(dsn_config)\n",
    "dsn_trainer = train.DSNTrainer(dsn, dsn_training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network for 1 epoch\n",
    "num_epochs = 1\n",
    "dsn_trainer.train(num_epochs, dl)\n",
    "dsn_trainer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(1, figsize=(15,3))\n",
    "total_subplots = 5\n",
    "starting_epoch = 0\n",
    "info_items = {k:v for (k,v) in dsn_trainer.infos.items() if k > starting_epoch}\n",
    "\n",
    "plt.subplot(1,total_subplots,1)\n",
    "losses = [x['loss'] for (k,x) in info_items.items()]\n",
    "plt.plot(info_items.keys(), losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Losses. {0}'.format(losses[-1]))\n",
    "\n",
    "plt.subplot(1,total_subplots,2)\n",
    "fg_losses = [x['FG loss'] for (k,x) in info_items.items()]\n",
    "plt.plot(info_items.keys(), fg_losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Foreground Losses. {0}'.format(fg_losses[-1]))\n",
    "\n",
    "plt.subplot(1,total_subplots,3)\n",
    "co_losses = [x['Center Offset loss'] for (k,x) in info_items.items()]\n",
    "plt.plot(info_items.keys(), co_losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Center Offset Losses. {0}'.format(co_losses[-1]))\n",
    "\n",
    "plt.subplot(1,total_subplots,4)\n",
    "sep_losses = [x['Separation loss'] for (k,x) in info_items.items()]\n",
    "plt.plot(info_items.keys(), sep_losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Separation Losses. {0}'.format(sep_losses[-1]))\n",
    "\n",
    "plt.subplot(1,total_subplots,5)\n",
    "cl_losses = [x['Cluster loss'] for (k,x) in info_items.items()]\n",
    "plt.plot(info_items.keys(), cl_losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Cluster Losses. {0}'.format(cl_losses[-1]))\n",
    "\n",
    "print(\"Number of iterations: {0}\".format(dsn_trainer.iter_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize some stuff\n",
    "\n",
    "Run the network on a single batch, and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = data_loader.get_TOD_test_dataloader(TOD_filepath, data_loading_params, batch_size=8, num_workers=8, shuffle=True)\n",
    "dl_iter = dl.__iter__()\n",
    "\n",
    "batch = next(dl_iter)\n",
    "rgb_imgs = util_.torch_to_numpy(batch['rgb'], is_standardized_image=True) # Shape: [N x H x W x 3]\n",
    "xyz_imgs = util_.torch_to_numpy(batch['xyz']) # Shape: [N x H x W x 3]\n",
    "foreground_labels = util_.torch_to_numpy(batch['foreground_labels']) # Shape: [N x H x W]\n",
    "center_offset_labels = util_.torch_to_numpy(batch['center_offset_labels']) # Shape: [N x 2 x H x W]\n",
    "N, H, W = foreground_labels.shape[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of images: {0}\".format(N))\n",
    "\n",
    "dsn.eval_mode()\n",
    "\n",
    "### Compute segmentation masks ###\n",
    "st_time = time()\n",
    "fg_masks, center_offsets, object_centers, initial_masks = dsn.run_on_batch(batch)\n",
    "total_time = time() - st_time\n",
    "print('Total time taken for Segmentation: {0} seconds'.format(round(total_time, 3)))\n",
    "print('FPS: {0}'.format(round(N / total_time,3)))\n",
    "\n",
    "# Get segmentation masks in numpy\n",
    "fg_masks = fg_masks.cpu().numpy()\n",
    "center_offsets = center_offsets.cpu().numpy().transpose(0,2,3,1)\n",
    "initial_masks = initial_masks.cpu().numpy()\n",
    "for i in range(len(object_centers)):\n",
    "    object_centers[i] = object_centers[i].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_index = 1\n",
    "for i in range(N):\n",
    "    \n",
    "    fig = plt.figure(fig_index); fig_index += 1\n",
    "    fig.set_size_inches(20,5)\n",
    "\n",
    "    # Plot image\n",
    "    plt.subplot(1,5,1)\n",
    "    plt.imshow(rgb_imgs[i,...].astype(np.uint8))\n",
    "    plt.title('Image {0}'.format(i+1))\n",
    "\n",
    "    # Plot Depth\n",
    "    plt.subplot(1,5,2)\n",
    "    plt.imshow(xyz_imgs[i,...,2])\n",
    "    plt.title('Depth')\n",
    "    \n",
    "    # Plot prediction\n",
    "    plt.subplot(1,5,3)\n",
    "    plt.imshow(util_.get_color_mask(fg_masks[i,...]))\n",
    "    plt.title(\"Predicted Masks\")\n",
    "    \n",
    "    # Plot Center Direction Predictions\n",
    "    plt.subplot(1,5,4)\n",
    "    fg_mask = np.expand_dims(fg_masks[i,...] == 2, axis=-1)\n",
    "    plt.imshow(flowlib.flow_to_image(direction_predictions[i,...] * fg_mask))\n",
    "    plt.title(\"Center Direction Predictions\")\n",
    "    \n",
    "    # Plot Initial Masks\n",
    "    plt.subplot(1,5,5)\n",
    "    plt.imshow(util_.get_color_mask(initial_masks[i,...]))\n",
    "    plt.title(f\"Initial Masks. #objects: {np.unique(initial_masks[i,...]).shape[0]-1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ssc]",
   "language": "python",
   "name": "conda-env-ssc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
